{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w266_Final Project_Game Review Sentiment Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/susandong/w266_final_project_game_sentiment/blob/master/w266_Final_Project_Game_Review_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrstJ8hJNJmO"
      },
      "source": [
        "# Final Project: Game Review Sentiment Analysis Over Time\n",
        "## Research Question: \n",
        "* Can we use sentiment analysis score to predict the active user base for video games over time\n",
        "\n",
        "## Dataset: \n",
        "* Game Review: twitter/reddit/discord/steam reviews\n",
        "* active user base: steam\n",
        "\n",
        "## Algorithm: \n",
        "* Baseline(logistic Regression); \n",
        "* Transformer(Elmo/Bert)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW01NUndQd3C"
      },
      "source": [
        "#Load libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFboN7cwMM6V"
      },
      "source": [
        "\"\"\" Download Data: There are 4 games with review data\n",
        "Fall Guys (fg)\n",
        "PlayerUnknown Battlegrounds (pubg)\n",
        "Dota 2 (dota2)\n",
        "Counterstrike Source: Go (csgo)\n",
        "\n",
        "Review data has the following columns:\n",
        "app: ID for the game\n",
        "useful: how many users voted the review as useful\n",
        "funny: how many users voted the review as funny\n",
        "username: username of the person who wrote the review\n",
        "games_owned: how many games the reviewer owns on Steam\n",
        "num_reviews: how many reviews the reviewer has written on Steam\n",
        "recommend: 1 for recommend (thumbs up), -1 for do not recommend (thumbs down)\n",
        "hours_played: number of hours the reviewer played before writing the review\n",
        "date: date review was written\n",
        "text: text of the review\n",
        "\"\"\"\n",
        "#Fall Guys\n",
        "fg_url = 'https://raw.githubusercontent.com/susandong/w266_final_project_game_sentiment/master/data/fallguys_reviews.csv'\n",
        "fg_df = pd.read_csv(fg_url, error_bad_lines=False)\n",
        "fg_df = fg_df.dropna()\n",
        "\n",
        "#CS: Go\n",
        "csgo_url = 'https://raw.githubusercontent.com/susandong/w266_final_project_game_sentiment/master/data/csgo_reviews.csv'\n",
        "csgo_df = pd.read_csv(csgo_url, error_bad_lines=False)\n",
        "csgo_df = csgo_df.dropna()\n",
        "\n",
        "#PUBG\n",
        "pubg_url = 'https://raw.githubusercontent.com/susandong/w266_final_project_game_sentiment/master/data/pubg_reviews.csv'\n",
        "pubg_df = pd.read_csv(pubg_url, error_bad_lines=False)\n",
        "pubg_df = pubg_df.dropna()\n",
        "\n",
        "#dota2_url = 'https://raw.githubusercontent.com/susandong/w266_final_project_game_sentiment/master/data/dota2_reviews.csv'\n",
        "#dota2_df = pd.read_csv(dota2_url, error_bad_lines=False)\n",
        "#player_url = 'https://raw.githubusercontent.com/susandong/w266_final_project_game_sentiment/master/data/PlayerCountData.csv'\n",
        "#player_df = pd.read_csv(player_url, error_bad_lines=False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq_wR2DmOp7T",
        "outputId": "1c075f70-8e2c-43e2-db37-d097e55863f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Data Preprocessing\n",
        "!pip install unidecode\n",
        "import unidecode\n",
        "import re\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "#from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "\n",
        "tknzr = TweetTokenizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "#lemma = WordNetLemmatizer()\n",
        "\n",
        "#Convert accented characters\n",
        "def remove_accents(text):\n",
        "  try:\n",
        "    text = unidecode.unidecode(text)\n",
        "  except:\n",
        "    pass\n",
        "  return text\n",
        "\n",
        "#Remove digits and punctuation\n",
        "def remove_nonletters(text):\n",
        "  try:\n",
        "    #Remove digits AND punctuation\n",
        "    #text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    \n",
        "    #Remove just digits that are by themselves\n",
        "    text = re.sub('^\\d+\\s|\\s\\d+\\s|\\s\\d+$', ' ', text)\n",
        "  except:\n",
        "    pass\n",
        "  return text\n",
        "\n",
        "\n",
        "#Use Tweet Tokenizer for some built-in emoji support\n",
        "def tweet_tokenization(text):\n",
        "  try:\n",
        "    return tknzr.tokenize(text)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "def remove_stopwords(token):\n",
        "  try:\n",
        "    return [item for item in token if item not in stop_words]\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "def remove_stemmer(token):\n",
        "  try:\n",
        "    return [stemmer.stem(i) for i in token]\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "def remove_lemmatizer(token):\n",
        "  try:\n",
        "    return [lemma.lemmatize(word=w, pow='v') for w in token]\n",
        "  except:\n",
        "    pass\n",
        "  \n",
        "def remove_shortwords(token):\n",
        "  try:\n",
        "    return [i for i in token if len(i) > 1]\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "def token_to_string(listTokens):\n",
        "  return ' '.join(listTokens)\n",
        "\n",
        "#Process text from dataframe. df = dataframe to clean, text = name of column with text\n",
        "def process_text(df, text):  \n",
        "  #Create new column for cleaned text\n",
        "  df['cleaned'] = df[text]\n",
        "\n",
        "  #Lower case all text\n",
        "  df['cleaned'] = df['cleaned'].str.lower()\n",
        "\n",
        "  #Clean URLs\n",
        "  df['cleaned'] = df['cleaned'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
        "\n",
        "  #Remove accents from text\n",
        "  df['cleaned'] = df['cleaned'].apply(remove_accents)\n",
        "\n",
        "  #Remove numbers and punctuation from text\n",
        "  df['cleaned'] = df['cleaned'].apply(remove_nonletters)\n",
        "  \n",
        "  #Tokenize\n",
        "  df['cleaned'] = df['cleaned'].apply(tweet_tokenization)\n",
        "\n",
        "  #Remove stopwords\n",
        "  df['cleaned'] = df['cleaned'].apply(remove_stopwords)\n",
        "  \n",
        "  #Remove short words\n",
        "  df['cleaned'] = df['cleaned'].apply(remove_shortwords)\n",
        "\n",
        "  #Stemming - can decide to use or not\n",
        "  #df['cleaned'] = df['cleaned'].apply(remove_stemmer)\n",
        "\n",
        "  #Convert tokens back to string\n",
        "  df['cleaned'] = df['cleaned'].apply(token_to_string)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahL3k7O7XGZ-"
      },
      "source": [
        "#preprocess all the datasets for all 3 games\n",
        "process_text(fg_df, 'text')\n",
        "#len(fg_df['cleaned'][11]) < 2\n",
        "process_text(csgo_df, 'text')\n",
        "process_text(pubg_df, 'text')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I3A02R2XgMn"
      },
      "source": [
        "#concatenate all 3 games data to one large dataset\n",
        "all_df=pd.concat([fg_df,csgo_df,pubg_df])\n",
        "all_clean_df=all_df[[\"recommend\",\"cleaned\"]]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agbZIEqVXgVQ"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "def remove_blankrow(df,column):\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  df['lens'] =[len(tokenizer.tokenize(utterance)) for utterance in df[column]]\n",
        "  df_clean=df[df['lens'] !=0]\n",
        "  return df_clean"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yLsbbrEXgYf",
        "outputId": "a3ab4d40-3c8f-47de-e4d0-c2e19f634922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "df_final=remove_blankrow(all_clean_df,'cleaned')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67rs7QtqXgbg",
        "outputId": "6e9f5346-3c44-4e1e-8194-31f390f7a8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_final.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(440882, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blE3XyBeuO5-",
        "outputId": "7017960b-4941-43b1-85c7-f9784b8a1bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "all_clean_df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(452858, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYO6zayauqLp",
        "outputId": "ce577cf2-7b43-47e3-fadd-fddfa812d070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "#check the length of reviews\n",
        "print(df_final.lens.describe())\n",
        "print(df_final['lens'].quantile(0.999))\n",
        "#remove the extremely long reviews\n",
        "df_final=df_final[df_final.lens<(df_final['lens'].quantile(0.999))]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    440882.000000\n",
            "mean         16.772234\n",
            "std          47.195142\n",
            "min           1.000000\n",
            "25%           2.000000\n",
            "50%           5.000000\n",
            "75%          14.000000\n",
            "max        7677.000000\n",
            "Name: lens, dtype: float64\n",
            "498.11900000006426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFSQvyP1wOO2",
        "outputId": "9ca3bfef-d7d1-45bf-ffb2-2a03e60ad7da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#check negative data vs positive data\n",
        "df_final.recommend.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    320468\n",
              "-1    119973\n",
              "Name: recommend, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W00n-Er7wsjf",
        "outputId": "8ccab99c-6125-40be-b51a-d40429d9957b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#balance the negative and positive data\n",
        "from sklearn.utils import resample\n",
        "\n",
        "df_majority = df_final[df_final.recommend==1]\n",
        "df_minority = df_final[df_final.recommend==-1]\n",
        "\n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=320468,    # to match majority class\n",
        "                                 random_state=235) # reproducible results\n",
        " \n",
        "# Combine majority class with upsampled minority class\n",
        "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
        " \n",
        "\n",
        "#replace outcome label -1 with 0\n",
        "df_balanced['recommend'] = df_balanced['recommend'].replace([-1],0)\n",
        "# Display new class counts\n",
        "df_balanced.recommend.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    320468\n",
              "0    320468\n",
              "Name: recommend, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szr37BDfOuVz"
      },
      "source": [
        "# Build model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LOQ82hNzPKw"
      },
      "source": [
        "# Simple CNN\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "max_features = 200000  # Only consider the top 20k words\n",
        "maxlen = 500\n",
        "embedding_dim = 16\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRSwS4BBzlWG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_balanced.cleaned,df_balanced.recommend,\n",
        "test_size=0.2)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW4JP3XXzleL"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import string\n",
        "import re\n",
        "layer = TextVectorization()\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0TWxo9szlhM",
        "outputId": "465c3439-56dd-4117-b6f7-2657c61cfd2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "#layer.adapt(X_train.values)\n",
        "vectorized_X_train = layer(X_train.values)\n",
        "vectorized_X_test = layer(X_test.values)\n",
        "print(vectorized_X_train)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1 1 0 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " ...\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]], shape=(512748, 494), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWXtEMuf2Jjp",
        "outputId": "2a97f47d-ddff-46e9-f081-e821cd00d123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "X_train.values"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['interesting personalities',\n",
              "       'worst game ever played paid prime status paired loyalty badges veteran coins half cheating got kicked calling people cheating given day ban competitive calling blatant cheaters see vods blatant empirical evidence players cheating prime status games 8/ 10 games hackers played games silver golden aks top fragged one cheating top constant hackers games get deal rigged gambling aspect csgo cases game pure tm tm tm tm tm tm tm trash recommend anyone invest money time complete piece garbage',\n",
              "       'good game highly addictive', ..., 'region lock china already',\n",
              "       'good game willing put hours honestly playing solo queue brutal hit level 21 get prime queued exclusively prime players basically players create account getting prime queue minimizes cheaters griefers matchmaking also tougher market game died little bit still strong csgo definitely unique aspects would try game also ... csgo valorant debate',\n",
              "       'game enough time figure good still broken many ways listing near impossible fix pubg complete failure roe peace'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To17agLQzlmH",
        "outputId": "ebbe8f37-e2eb-46a7-c8b1-117d3021d168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(layers.Embedding(max_features + 1, embedding_dim))\n",
        "#model.layers[0].trainable = False\n",
        "#model.add(layers.Dropout(0.05))\n",
        "model.add(layers.GlobalAveragePooling1D())\n",
        "#model.add(layers.Dropout(0.05))\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=\"accuracy\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          3200016   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 3,200,033\n",
            "Trainable params: 3,200,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3Z4Be4nzlp7"
      },
      "source": [
        "#train model\n",
        "#epochs = 10\n",
        "#history = model.fit(\n",
        " #   vectorized_X_train,y_train,\n",
        " #   epochs=epochs,batch_size=32)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hvcHJYPBQYj"
      },
      "source": [
        "# evaluate model\n",
        "#model.evaluate(vectorized_X_test, y_test, batch_size=512)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJwBYEowO2pk"
      },
      "source": [
        "#BERT model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO0QlEWmzj-r"
      },
      "source": [
        "tf.config.set_soft_device_placement(True)\n",
        "tf.debugging.set_log_device_placement(True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHbZ0Xo73rcB"
      },
      "source": [
        "\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "import io\n",
        "import re\n",
        "\n",
        "import pickle\n",
        "from csv import reader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "from datetime import datetime\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq2PaC0z3044",
        "outputId": "4e8ea9de-e05d-4b7c-9d85-c164405d59b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, TFBertModel"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmunBVBe6zrx"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHcYnsGU7Qx7"
      },
      "source": [
        "class GameReviewData:\n",
        "    DATA_COLUMN = \"cleaned\"\n",
        "    LABEL_COLUMN = \"recommend\"\n",
        "\n",
        "    def __init__(self, train, test, tokenizer, classes, max_seq_len=192):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_len = 0\n",
        "        self.classes = classes\n",
        "    \n",
        "        ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self._prepare, [train, test])\n",
        "\n",
        "        print(\"max seq_len\", self.max_seq_len)\n",
        "        self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
        "        self.train_x, self.test_x = map(self._pad, [self.train_x, self.test_x])\n",
        "\n",
        "    def _prepare(self, df):\n",
        "        x, y = [], []\n",
        "    \n",
        "        for _, row in tqdm(df.iterrows()):\n",
        "            text, label = row[GameReviewData.DATA_COLUMN], row[GameReviewData.LABEL_COLUMN]\n",
        "            tokens = self.tokenizer.tokenize(text)\n",
        "            tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "            token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "            self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
        "            x.append(token_ids)\n",
        "            y.append(self.classes.index(label))\n",
        "\n",
        "        return np.array(x), np.array(y)\n",
        "\n",
        "    def _pad(self, ids):\n",
        "        x = []\n",
        "        for input_ids in ids:\n",
        "            input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
        "            input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
        "            x.append(np.array(input_ids))\n",
        "        return np.array(x)\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlpRCXbRBvbe"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train,test= train_test_split(df_balanced,\n",
        "test_size=0.2)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvKKOZZOHs2t",
        "outputId": "8cacde2a-84d9-4ca2-8ee0-2a2e12faafa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classes = df_balanced.recommend.unique().tolist()\n",
        "classes"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIg9CU8mDRVk",
        "outputId": "adbb013d-2718-4798-a6d2-eb594563cdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "processed_data= GameReviewData(train,test, tokenizer, [0,1], max_seq_len=50)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512748it [04:12, 2032.96it/s]\n",
            "128188it [01:04, 2000.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max seq_len 2661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aRB43nIL3_m",
        "outputId": "5f4d5b56-9ac5-4b65-d5aa-dc574ef84e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "processed_data.train_x[0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101, 11030,  1403, 23078,   102,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IudtFZHqKVNi",
        "outputId": "30aa991a-8a20-4ec8-fe19-5e245cbda4c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "bert_layer = TFBertModel.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SZ7uHMJMvpf"
      },
      "source": [
        "def create_model(max_seq_len,train_layers):\n",
        "    \n",
        "  input_ids      = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"input_ids\")\n",
        "  \n",
        "   \n",
        "  bert_inputs = [input_ids]\n",
        "# Freeze layers, i.e. only train number of layers specified, starting from the top\n",
        "    \n",
        "  if not train_layers == -1:\n",
        "        \n",
        "    retrain_layers = []\n",
        "    \n",
        "    for retrain_layer_number in range(train_layers):\n",
        "\n",
        "      layer_code = '_' + str(11 - retrain_layer_number)\n",
        "      retrain_layers.append(layer_code)\n",
        "\n",
        "    for w in bert_layer.weights:\n",
        "      if not any([x in w.name for x in retrain_layers]):\n",
        "              w._trainable = False\n",
        "\n",
        "     # End of freezing section\n",
        "\n",
        "  output         = bert_layer(bert_inputs)[0]\n",
        "  print(output.shape)\n",
        "  #cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(output)\n",
        "  #cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
        "  logits = keras.layers.Dense(units=256, activation=\"relu\")(output)\n",
        "  logits = keras.layers.Dropout(0.1)(logits)\n",
        "  logits = keras.layers.Dense(units=1, activation=\"sigmoid\")(logits)\n",
        "\n",
        "  model = keras.Model(inputs=input_ids, outputs=logits)\n",
        "  model.build(input_shape=(None, max_seq_len))\n",
        "\n",
        "\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
        "                loss=\"binary_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOhMZLN6Kiog",
        "outputId": "0d9c8412-bf7c-4b2f-b424-613abc70b776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "model = create_model(processed_data.max_seq_len,train_layers=0)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 50, 768)\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_ids (InputLayer)       [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model (TFBertModel)  ((None, 50, 768), (None,  108310272 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50, 256)           196864    \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 50, 256)           0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50, 1)             257       \n",
            "=================================================================\n",
            "Total params: 108,507,393\n",
            "Trainable params: 108,507,393\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apCBGtQAx85H",
        "outputId": "ac0934c6-7b11-42c5-8f34-3d17ffacc612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "tf.config.set_soft_device_placement(True)\n",
        "tf.debugging.set_log_device_placement(True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbfn41V_SSMo",
        "outputId": "71745f44-8929-4ffd-d041-780a04989658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "import datetime\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "log_dir = \"log/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "history = model.fit(\n",
        "  x=processed_data.train_x, \n",
        "  y=processed_data.train_y,\n",
        "  validation_split=0.1,\n",
        "  batch_size=128,\n",
        "  shuffle=True,\n",
        "  epochs=5,\n",
        "  callbacks=[tensorboard_callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/embeddings/word_embeddings/weight:0', 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_model/bert/embeddings/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "   1/3606 [..............................] - ETA: 1s - loss: 0.6812 - accuracy: 0.5925WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "3606/3606 [==============================] - 1890s 524ms/step - loss: 0.6192 - accuracy: 0.6662 - val_loss: 0.6111 - val_accuracy: 0.6765\n",
            "Epoch 2/5\n",
            "2489/3606 [===================>..........] - ETA: 8:47 - loss: 0.6009 - accuracy: 0.6821"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTj8cVwe9AN8"
      },
      "source": [
        "model.evaluate(processed_data.test_x,processed_data.test_y,batch_size=1048)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAyxg7J79Amh"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOxU41L59F6S"
      },
      "source": [
        "%tensorboard --logdir log"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}